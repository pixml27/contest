{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_uid</th>\n",
       "      <th>element_uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>571252</td>\n",
       "      <td>1364</td>\n",
       "      <td>10</td>\n",
       "      <td>4.430517e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63140</td>\n",
       "      <td>3037</td>\n",
       "      <td>10</td>\n",
       "      <td>4.430514e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443817</td>\n",
       "      <td>4363</td>\n",
       "      <td>8</td>\n",
       "      <td>4.430514e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>359870</td>\n",
       "      <td>1364</td>\n",
       "      <td>10</td>\n",
       "      <td>4.430506e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>359870</td>\n",
       "      <td>3578</td>\n",
       "      <td>9</td>\n",
       "      <td>4.430506e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_uid  element_uid  rating            ts\n",
       "0    571252         1364      10  4.430517e+07\n",
       "1     63140         3037      10  4.430514e+07\n",
       "2    443817         4363       8  4.430514e+07\n",
       "3    359870         1364      10  4.430506e+07\n",
       "4    359870         3578       9  4.430506e+07"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "DATA_PATH = 'D:\\download'\n",
    "transactions = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'transactions.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'consumption_mode': 'category',\n",
    "        'ts': np.float64,\n",
    "        'watched_time': np.uint64,\n",
    "        'device_type': np.uint8,\n",
    "        'device_manufacturer': np.uint8\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#transactions_exp = pd.read_csv(\n",
    "#    os.path.join(DATA_PATH, 'transactions_exp.csv'),\n",
    "    \n",
    "#)\n",
    "\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'ratings.csv'),\n",
    "    dtype={\n",
    "        'element_uid': np.uint16,\n",
    "        'user_uid': np.uint32,\n",
    "        'ts': np.float64,\n",
    "        'rating': np.uint8\n",
    "    }\n",
    ")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transactions_exp = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'transactions_exp2.csv'),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_exp=transactions_exp.replace([np.inf], np.nan)\n",
    "transactions_exp.watched_time=transactions_exp.watched_time.fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9643012 entries, 0 to 9643011\n",
      "Data columns (total 33 columns):\n",
      "Unnamed: 0        int64\n",
      "Unnamed: 0.1      int64\n",
      "Unnamed: 0.1.1    int64\n",
      "element_uid       int32\n",
      "user_uid          int32\n",
      "watched_time      float64\n",
      "rating            float64\n",
      "duration          int16\n",
      "feature_1         float64\n",
      "feature_2         float64\n",
      "feature_3         int16\n",
      "feature_4         float64\n",
      "quantity          int64\n",
      "rating_mean       float64\n",
      "CM_S              int64\n",
      "CM_P              int64\n",
      "CM_R              int64\n",
      "feature_5_65      int16\n",
      "feature_5_00      int16\n",
      "feature_5_68      int16\n",
      "feature_5_59      int16\n",
      "feature_5_-1      int16\n",
      "feature_5_44      int64\n",
      "smallf3           int16\n",
      "middlef3          int16\n",
      "bigf3             int16\n",
      "type_m            int16\n",
      "type_s            int16\n",
      "type_mm           int16\n",
      "longfilm          int64\n",
      "shortfilm         int64\n",
      "worst             int64\n",
      "watched           int64\n",
      "dtypes: float64(6), int16(13), int32(2), int64(12)\n",
      "memory usage: 1.6 GB\n"
     ]
    }
   ],
   "source": [
    "transactions_exp['feature_5_65']=transactions_exp['feature_5_65'].astype(np.int16)\n",
    "transactions_exp['feature_5_00']=transactions_exp['feature_5_00'].astype(np.int16)\n",
    "transactions_exp['feature_5_68']=transactions_exp['feature_5_68'].astype(np.int16)\n",
    "transactions_exp['feature_5_59']=transactions_exp['feature_5_59'].astype(np.int16)\n",
    "transactions_exp['feature_5_-1']=transactions_exp['feature_5_-1'].astype(np.int16)\n",
    "transactions_exp['smallf3']= transactions_exp['smallf3'].astype(np.int16)\n",
    "transactions_exp['middlef3']=transactions_exp['middlef3'].astype(np.int16)\n",
    "transactions_exp['bigf3']=transactions_exp['bigf3'].astype(np.int16)\n",
    "\n",
    "transactions_exp['type_m']=transactions_exp['type_m'].astype(np.int16)\n",
    "\n",
    "transactions_exp['type_s']=transactions_exp['type_s'].astype(np.int16)\n",
    "\n",
    "transactions_exp['type_mm']= transactions_exp['type_mm'].astype(np.int16)\n",
    "\n",
    "transactions_exp['feature_3']=transactions_exp['feature_3'].astype(np.int16)\n",
    "\n",
    "transactions_exp['duration']=transactions_exp['duration'].astype(np.int16)\n",
    "\n",
    "transactions_exp['element_uid']=transactions_exp['element_uid'].astype(np.int32)\n",
    "transactions_exp['user_uid']=transactions_exp['user_uid'].astype(np.int32)\n",
    "transactions_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element_uid     0\n",
      "user_uid        0\n",
      "watched_time    0\n",
      "rating          0\n",
      "duration        0\n",
      "feature_2       0\n",
      "feature_3       0\n",
      "feature_4       0\n",
      "quantity        0\n",
      "rating_mean     0\n",
      "CM_S            0\n",
      "CM_P            0\n",
      "CM_R            0\n",
      "feature_5_65    0\n",
      "feature_5_00    0\n",
      "feature_5_68    0\n",
      "feature_5_59    0\n",
      "feature_5_-1    0\n",
      "feature_5_44    0\n",
      "smallf3         0\n",
      "middlef3        0\n",
      "bigf3           0\n",
      "type_m          0\n",
      "type_s          0\n",
      "type_mm         0\n",
      "longfilm        0\n",
      "shortfilm       0\n",
      "watched         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9643012 entries, 0 to 9643011\n",
      "Data columns (total 28 columns):\n",
      "element_uid     int32\n",
      "user_uid        int32\n",
      "watched_time    float64\n",
      "rating          float64\n",
      "duration        int16\n",
      "feature_2       float64\n",
      "feature_3       int16\n",
      "feature_4       float64\n",
      "quantity        int64\n",
      "rating_mean     float64\n",
      "CM_S            int64\n",
      "CM_P            int64\n",
      "CM_R            int64\n",
      "feature_5_65    int16\n",
      "feature_5_00    int16\n",
      "feature_5_68    int16\n",
      "feature_5_59    int16\n",
      "feature_5_-1    int16\n",
      "feature_5_44    int64\n",
      "smallf3         int16\n",
      "middlef3        int16\n",
      "bigf3           int16\n",
      "type_m          int16\n",
      "type_s          int16\n",
      "type_mm         int16\n",
      "longfilm        int64\n",
      "shortfilm       int64\n",
      "watched         int64\n",
      "dtypes: float64(5), int16(13), int32(2), int64(8)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "transactions_exp=transactions_exp.drop(['Unnamed: 0', 'Unnamed: 0.1', 'Unnamed: 0.1.1', 'feature_1', 'worst'],1)\n",
    "print(np.isinf(transactions_exp).sum())\n",
    "transactions_exp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train = transactions_exp[~transactions_exp.rating.isnull()]\n",
    "X_train=X_train.drop(['rating'],1)\n",
    "X_test = transactions_exp[transactions_exp.rating.isnull()]\n",
    "X_test=X_test.drop(['rating'],1)\n",
    "y_train = transactions_exp[~transactions_exp.rating.isnull()].rating.astype(np.float)\n",
    "y_test = transactions_exp[transactions_exp.rating.isnull()].rating\n",
    "X_test.rating_mean=X_test.rating_mean.fillna(6.0) #попробовать на всех"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model2 = RandomForestRegressor( n_estimators=522, max_depth=8, random_state=241, n_jobs=-1)\n",
    "model2.fit(X_train, y_train)\n",
    "submit1 = pd.DataFrame(model2.predict(X_test))\n",
    "\n",
    "\n",
    "X_test=X_test.drop([\n",
    "    'rating_mean',\n",
    "'watched_time',    \n",
    "'duration'  ,      \n",
    "'feature_2'  ,   \n",
    "'feature_3'  ,   \n",
    "'feature_4'  ,   \n",
    "'quantity'  ,    \n",
    "'CM_S'  ,        \n",
    "'CM_P',  \n",
    "'CM_R'  ,        \n",
    "'feature_5_65' , \n",
    "'feature_5_00'  ,\n",
    "'feature_5_68'  ,\n",
    "'feature_5_59'  ,\n",
    "'feature_5_-1'  ,\n",
    "'feature_5_44'  ,\n",
    "'smallf3' ,      \n",
    "'middlef3'  ,    \n",
    "'bigf3',         \n",
    "'type_m',     \n",
    "'type_s'  ,      \n",
    "'type_mm' ], 1)\n",
    "#submit[0]=submit[0].round()\n",
    "#submit[0]=submit[0].astype(np.int16)\n",
    "X_test=X_test.reset_index()\n",
    "X_test=X_test.drop(['index'], 1)\n",
    "X_test=X_test.drop(['watched'], 1)\n",
    "X_test=X_test.drop(['longfilm', 'shortfilm'], 1)\n",
    "\n",
    "OLD=pd.concat([X_test, submit1], 1)\n",
    "#OLD.rating=OLD.rating.round()\n",
    "OLD['rating']=OLD[0]\n",
    "OLD=OLD.drop([0],1)\n",
    "#ratings=ratings.drop(['ts'],1)\n",
    "OLD2 = OLD.append(ratings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1722310 entries, 24 to 9642999\n",
      "Data columns (total 32 columns):\n",
      "Unnamed: 0      int64\n",
      "Unnamed: 0.1    int64\n",
      "element_uid     int64\n",
      "user_uid        int64\n",
      "watched_time    float64\n",
      "rating          float64\n",
      "duration        int64\n",
      "feature_1       float64\n",
      "feature_2       float64\n",
      "feature_3       int64\n",
      "feature_4       float64\n",
      "quantity        int64\n",
      "rating_mean     float64\n",
      "CM_S            int64\n",
      "CM_P            int64\n",
      "CM_R            int64\n",
      "feature_5_65    int64\n",
      "feature_5_00    int64\n",
      "feature_5_68    int64\n",
      "feature_5_59    int64\n",
      "feature_5_-1    int64\n",
      "feature_5_44    int64\n",
      "smallf3         int64\n",
      "middlef3        int64\n",
      "bigf3           int64\n",
      "type_m          int64\n",
      "type_s          int64\n",
      "type_mm         int64\n",
      "longfilm        int64\n",
      "shortfilm       int64\n",
      "worst           int64\n",
      "watched         int64\n",
      "dtypes: float64(6), int64(26)\n",
      "memory usage: 433.6 MB\n"
     ]
    }
   ],
   "source": [
    "del transactions_exp\n",
    "\n",
    "transactions_exp = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'transactions_exp.csv'),\n",
    "    \n",
    ")\n",
    "transactions_exp1=transactions_exp\n",
    "\n",
    "transactions_exp1['worst']=transactions_exp1.watched_time.map(lambda x:1 if x < 0.2 and x >0.005 else 0)\n",
    "transactions_exp1['watched']=transactions_exp1.watched_time.map(lambda x: 0 if x < 0.51 else 1)\n",
    "\n",
    "Test=transactions_exp1[transactions_exp1['worst'] == 1]   \n",
    "                                                                   \n",
    "\n",
    "\n",
    "submit2=Test[Test.rating.isnull() == True]\n",
    "submit2.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "submit2['feature_5_65']=submit2['feature_5_65'].astype(np.int16)\n",
    "submit2['feature_5_00']=submit2['feature_5_00'].astype(np.int16)\n",
    "submit2['feature_5_68']=submit2['feature_5_68'].astype(np.int16)\n",
    "submit2['feature_5_59']=submit2['feature_5_59'].astype(np.int16)\n",
    "submit2['feature_5_-1']=submit2['feature_5_-1'].astype(np.int16)\n",
    "submit2['smallf3']= submit2['smallf3'].astype(np.int16)\n",
    "submit2['middlef3']=submit2['middlef3'].astype(np.int16)\n",
    "submit2['bigf3']=submit2['bigf3'].astype(np.int16)\n",
    "\n",
    "submit2['type_m']=submit2['type_m'].astype(np.int16)\n",
    "\n",
    "submit2['type_s']=submit2['type_s'].astype(np.int16)\n",
    "\n",
    "submit2['type_mm']= submit2['type_mm'].astype(np.int16)\n",
    "\n",
    "submit2['feature_3']=submit2['feature_3'].astype(np.int16)\n",
    "\n",
    "submit2['duration']=submit2['duration'].astype(np.int16)\n",
    "\n",
    "submit2['element_uid']=submit2['element_uid'].astype(np.int32)\n",
    "submit2['user_uid']=submit2['user_uid'].astype(np.int32)\n",
    "\n",
    "\n",
    "submit2=submit2.drop(['Unnamed: 0', 'Unnamed: 0.1', 'feature_1'],1)\n",
    "submit2=submit2.drop(['worst', 'rating'],1)\n",
    "submit2.rating_mean=submit2.rating_mean.fillna(6.0)\n",
    "\n",
    "submit22 = pd.DataFrame(model2.predict(submit2))\n",
    "\n",
    "\n",
    "submit2=submit2.drop([\n",
    "    'rating_mean',\n",
    "'watched_time',    \n",
    "'duration'  ,      \n",
    "'feature_2'  ,   \n",
    "'feature_3'  ,   \n",
    "'feature_4'  ,   \n",
    "'quantity'  ,    \n",
    "'CM_S'  ,        \n",
    "'CM_P',  \n",
    "'CM_R'  ,        \n",
    "'feature_5_65' , \n",
    "'feature_5_00'  ,\n",
    "'feature_5_68'  ,\n",
    "'feature_5_59'  ,\n",
    "'feature_5_-1'  ,\n",
    "'feature_5_44'  ,\n",
    "'smallf3' ,      \n",
    "'middlef3'  ,    \n",
    "'bigf3',         \n",
    "'type_m',     \n",
    "'type_s'  ,      \n",
    "'type_mm' ], 1)\n",
    "#submit[0]=submit[0].round()\n",
    "#submit[0]=submit[0].astype(np.int16)\n",
    "submit2=submit2.reset_index()\n",
    "submit2=submit2.drop(['index'], 1)\n",
    "submit2=submit2.drop(['watched'], 1)\n",
    "submit2=submit2.drop(['longfilm', 'shortfilm'], 1)\n",
    "\n",
    "OLD333=pd.concat([submit2, submit22], 1)\n",
    "#OLD.rating=OLD.rating.round()\n",
    "OLD333['rating']=OLD333[0]\n",
    "OLD333=OLD333.drop([0],1)\n",
    "#ratings=ratings.drop(['ts'],1)\n",
    "OLD2 = OLD2.append(OLD333)\n",
    "\n",
    "\n",
    "OLD2.to_csv(os.path.join(DATA_PATH, 'OLD2(doobuch).csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1753282 entries, 24 to 9642999\n",
      "Data columns (total 26 columns):\n",
      "element_uid     int32\n",
      "user_uid        int32\n",
      "watched_time    float64\n",
      "duration        int16\n",
      "feature_2       float64\n",
      "feature_3       int16\n",
      "feature_4       float64\n",
      "quantity        int64\n",
      "rating_mean     float64\n",
      "CM_S            int64\n",
      "CM_P            int64\n",
      "CM_R            int64\n",
      "feature_5_65    int16\n",
      "feature_5_00    int16\n",
      "feature_5_68    int16\n",
      "feature_5_59    int16\n",
      "feature_5_-1    int16\n",
      "feature_5_44    int64\n",
      "smallf3         int16\n",
      "middlef3        int16\n",
      "bigf3           int16\n",
      "type_m          int16\n",
      "type_s          int16\n",
      "type_mm         int16\n",
      "longfilm        int64\n",
      "shortfilm       int64\n",
      "dtypes: float64(4), int16(13), int32(2), int64(7)\n",
      "memory usage: 217.4 MB\n"
     ]
    }
   ],
   "source": [
    "submit2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is -0.625218053017624\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c2304010609c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score is\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0msubmit1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0msubmit1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sample_submissionrf02.03.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241) \n",
    "\n",
    "\n",
    "model2 = RandomForestRegressor( n_estimators=522, max_depth=8, random_state=241, n_jobs=-1)\n",
    "score=cross_val_score(model2, X_train, y_train, cv=kf, n_jobs=-1, scoring='mean_squared_error')\n",
    "print(\"Score is\", score.mean())\n",
    "model2.fit(X_train, y_train)\n",
    "submit1 = pd.DataFrame(estimator.predict(X_test))\n",
    "submit1.to_csv(\"sample_submissionrf02.03.csv\")\n",
    "\n",
    "\n",
    "estimator=xgb.XGBRegressor(learning_rate=0.1, max_depth=8, n_estimators=700, n_jobs=-1  )\n",
    "score1=cross_val_score(estimator, X_train, y_train, cv=kf, n_jobs=-1, scoring='mean_squared_error')\n",
    "print(\"Score is\", score1.mean())\n",
    "estimator.fit(X_train, y_train)\n",
    "submit = pd.DataFrame(estimator.predict(X_test))\n",
    "submit.to_csv(\"sample_submissionxgb02.03.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is -0.614842092771812\n"
     ]
    }
   ],
   "source": [
    "estimator=xgb.XGBRegressor(learning_rate=0.1, max_depth=8, n_estimators=700, n_jobs=-1  )\n",
    "score1=cross_val_score(estimator, X_train, y_train, cv=kf, n_jobs=-1, scoring='mean_squared_error')\n",
    "print(\"Score is\", score1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "one\n",
      "two\n"
     ]
    }
   ],
   "source": [
    "print('start')\n",
    "model2.fit(X_train, y_train)\n",
    "submit1 = pd.DataFrame(model2.predict(X_test))\n",
    "submit1.to_csv(\"sample_submissionrf02.03.csv\")\n",
    "print('one')\n",
    "estimator.fit(X_train, y_train)\n",
    "submit = pd.DataFrame(estimator.predict(X_test))\n",
    "submit.to_csv(\"sample_submissionxgb02.03.csv\")\n",
    "print('two')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model2 = RandomForestRegressor( n_estimators=522, max_depth=8, random_state=241)\n",
    "score=cross_val_score(model2, X_train, y_train, cv=kf, n_jobs=-1, scoring='mean_squared_error')\n",
    "#model2=model2.fit(X_train, y_train)\n",
    "#submit = pd.DataFrame(model2.predict(X_test)) #500 и 8 в итоге заиграли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(X_train, y_train)\n",
    "submit = pd.DataFrame(estimator.predict(X_test))\n",
    "submit.to_csv(\"sample_submissionxgb.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522 -3.3525222034319064 это поиск по деревьям\n"
     ]
    }
   ],
   "source": [
    "Score is -3.327374027489791\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241) \n",
    "\n",
    "\n",
    "grid = {'n_estimators': [521,522,523]}\n",
    "model = RandomForestRegressor( max_depth=4, random_state=241)\n",
    "gs = GridSearchCV(model, grid, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "Cb=gs.best_params_['n_estimators']\n",
    "Sb=gs.best_score_ \n",
    "print (Cb, Sb, 'это поиск по деревьям')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 -3.336118804707078 это поиск по глубине\n"
     ]
    }
   ],
   "source": [
    "\n",
    "grid1 = {'max_depth': [6,7,8,9]}\n",
    "model1 = RandomForestRegressor( n_estimators=Cb, random_state=241)\n",
    "gs1 = GridSearchCV(model1, grid1, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "gs1.fit(X_train, y_train)\n",
    "Cb1=gs1.best_params_['max_depth']\n",
    "Sb1=gs1.best_score_\n",
    "print (Cb1, Sb1, 'это поиск по глубине')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model2 = RandomForestRegressor( n_estimators=522, max_depth=8, random_state=241)\n",
    "model2=model2.fit(X_train, y_train)\n",
    "submit = pd.DataFrame(model2.predict(X_test)) #500 и 8 в итоге заиграли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      " 1. feature 'watched_time' (0.9713)\n",
      " 2. feature 'rating_mean' (0.0256)\n",
      " 3. feature 'CM_S ' (0.0015)\n",
      " 4. feature 'quantity' (0.0005)\n",
      " 5. feature 'user_uid' (0.0002)\n",
      " 6. feature 'duration' (0.0002)\n",
      " 7. feature 'CM_P ' (0.0002)\n",
      " 8. feature 'CM_R ' (0.0001)\n",
      " 9. feature 'feature_2' (0.0001)\n",
      "10. feature 'feature_3' (0.0001)\n",
      "11. feature 'element_uid' (0.0001)\n",
      "12. feature 'feature_4' (0.0001)\n",
      "13. feature 'type_mm' (0.0000)\n",
      "14. feature 'type_m' (0.0000)\n",
      "15. feature 'feature_5_44' (0.0000)\n",
      "16. feature 'feature_5_65' (0.0000)\n",
      "17. feature 'longfilm' (0.0000)\n",
      "18. feature 'type_s' (0.0000)\n",
      "19. feature 'feature_5_00' (0.0000)\n",
      "20. feature 'feature_5_68' (0.0000)\n",
      "21. feature 'feature_5_59' (0.0000)\n",
      "22. feature 'middlef3' (0.0000)\n",
      "23. feature 'feature_5_-1' (0.0000)\n",
      "24. feature 'shortfilm' (0.0000)\n",
      "25. feature 'bigf3' (0.0000)\n",
      "26. feature 'smallf3' (0.0000)\n",
      "27. feature 'watched' (0.0000)\n"
     ]
    }
   ],
   "source": [
    "importances = model2.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feature_names=X_train.columns\n",
    "print(\"Feature importances:\")\n",
    "for f, idx in enumerate(indices):\n",
    "    print(\"{:2d}. feature '{:5}' ({:.4f})\".format(f + 1, feature_names[idx], importances[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model2 = RandomForestRegressor( n_estimators=500, max_depth=8, random_state=241)\n",
    "model2=model2.fit(X_train, y_train)\n",
    "submit = pd.DataFrame(model2.predict(X_test)) #500 и 8 в итоге заиграли"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 -3.8074985438316618 это поиск по соседям\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=241) \n",
    "grid3 = {'n_neighbors': [28,29,30,31,32,33]}\n",
    "\n",
    "neigh = KNeighborsRegressor()\n",
    "gs3 = GridSearchCV(neigh, grid3, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
    "gs3.fit(X_train, y_train)\n",
    "Cb3=gs3.best_params_['n_neighbors']\n",
    "Sb3=gs3.best_score_\n",
    "print (Cb3, Sb3, 'это поиск по соседям')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6962767 entries, 0 to 6962766\n",
      "Data columns (total 3 columns):\n",
      "element_uid    int32\n",
      "user_uid       int32\n",
      "watched        int64\n",
      "dtypes: int32(2), int64(1)\n",
      "memory usage: 106.2 MB\n"
     ]
    }
   ],
   "source": [
    "X_test=X_test.drop([\n",
    "    'rating_mean',\n",
    "'watched_time',    \n",
    "'duration'  ,      \n",
    "'feature_2'  ,   \n",
    "'feature_3'  ,   \n",
    "'feature_4'  ,   \n",
    "'quantity'  ,    \n",
    "'CM_S'  ,        \n",
    "'CM_P',  \n",
    "'CM_R'  ,        \n",
    "'feature_5_65' , \n",
    "'feature_5_00'  ,\n",
    "'feature_5_68'  ,\n",
    "'feature_5_59'  ,\n",
    "'feature_5_-1'  ,\n",
    "'feature_5_44'  ,\n",
    "'smallf3' ,      \n",
    "'middlef3'  ,    \n",
    "'bigf3',         \n",
    "'type_m',     \n",
    "'type_s'  ,      \n",
    "'type_mm' ], 1)\n",
    "#submit[0]=submit[0].round()\n",
    "#submit[0]=submit[0].astype(np.int16)\n",
    "X_test=X_test.reset_index()\n",
    "X_test=X_test.drop(['index'], 1)\n",
    "X_test=X_test.drop(['watched'], 1)\n",
    "X_test=X_test.drop(['longfilm', 'shortfilm'], 1)\n",
    "\n",
    "OLD=pd.concat([X_test, submit1], 1)\n",
    "#OLD.rating=OLD.rating.round()\n",
    "OLD['rating']=OLD[0]\n",
    "OLD=OLD.drop([0],1)\n",
    "#ratings=ratings.drop(['ts'],1)\n",
    "OLD2 = OLD.append(ratings)\n",
    "\n",
    "\n",
    "transactions_exp=transactions_exp.drop([\n",
    "    'rating_mean',\n",
    "'watched_time',    \n",
    "'duration'  ,      \n",
    "'feature_2'  ,   \n",
    "'feature_3'  ,   \n",
    "'feature_4'  ,   \n",
    "'quantity'  ,    \n",
    "'CM_S'  ,        \n",
    "'CM_P',  \n",
    "'CM_R'  ,        \n",
    "'feature_5_65' , \n",
    "'feature_5_00'  ,\n",
    "'feature_5_68'  ,\n",
    "'feature_5_59'  ,\n",
    "'feature_5_-1'  ,\n",
    "'feature_5_44'  ,\n",
    "'smallf3' ,      \n",
    "'middlef3'  ,    \n",
    "'bigf3',         \n",
    "'type_m',     \n",
    "'type_s'  ,      \n",
    "'type_mm',\n",
    "'Unnamed: 0',\n",
    "'Unnamed: 0.1',\n",
    "'Unnamed: 0.1.1',\n",
    "'feature_1',\n",
    "'longfilm',\n",
    "'shortfilm',\n",
    "'watched',\n",
    "'worst' ], 1)\n",
    "\n",
    "OLD2=OLD2.append(transactions_exp)\n",
    "\n",
    "\n",
    "OLD2.to_csv(os.path.join(DATA_PATH, 'OLD_tr_1.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7401557 entries, 0 to 438789\n",
      "Data columns (total 4 columns):\n",
      "element_uid    int32\n",
      "rating         float32\n",
      "ts             float64\n",
      "user_uid       int64\n",
      "dtypes: float32(1), float64(1), int32(1), int64(1)\n",
      "memory usage: 225.9 MB\n"
     ]
    }
   ],
   "source": [
    "OLD=pd.concat([X_test, submit1], 1)\n",
    "#OLD.rating=OLD.rating.round()\n",
    "OLD['rating']=OLD[0]\n",
    "OLD=OLD.drop([0],1)\n",
    "#ratings=ratings.drop(['ts'],1)\n",
    "OLD2 = OLD.append(ratings)\n",
    "\n",
    "transactions_exp=transactions_exp.drop([\n",
    "    'rating_mean',\n",
    "'watched_time',    \n",
    "'duration'  ,      \n",
    "'feature_2'  ,   \n",
    "'feature_3'  ,   \n",
    "'feature_4'  ,   \n",
    "'quantity'  ,    \n",
    "'CM_S'  ,        \n",
    "'CM_P',  \n",
    "'CM_R'  ,        \n",
    "'feature_5_65' , \n",
    "'feature_5_00'  ,\n",
    "'feature_5_68'  ,\n",
    "'feature_5_59'  ,\n",
    "'feature_5_-1'  ,\n",
    "'feature_5_44'  ,\n",
    "'smallf3' ,      \n",
    "'middlef3'  ,    \n",
    "'bigf3',         \n",
    "'type_m',     \n",
    "'type_s'  ,      \n",
    "'type_mm',\n",
    "'Unnamed: 0',\n",
    "'Unnamed: 0.1',\n",
    "'Unnamed: 0.1.1',\n",
    "'feature_1',\n",
    "'longfilm',\n",
    "'shortfilm',\n",
    "'watched',\n",
    "'worst' ], 1)\n",
    "\n",
    "OLD2=OLD2.append(transactions_exp)\n",
    "\n",
    "\n",
    "OLD2.to_csv(os.path.join(DATA_PATH, 'OLD_tr_1.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7401557 entries, 0 to 438789\n",
      "Data columns (total 4 columns):\n",
      "element_uid    int32\n",
      "rating         float64\n",
      "ts             float64\n",
      "user_uid       int64\n",
      "dtypes: float64(2), int32(1), int64(1)\n",
      "memory usage: 254.1 MB\n"
     ]
    }
   ],
   "source": [
    "OLD=pd.concat([X_test, submit1], 1)\n",
    "#OLD.rating=OLD.rating.round()\n",
    "OLD['rating']=OLD[0]\n",
    "OLD=OLD.drop([0],1)\n",
    "#ratings=ratings.drop(['ts'],1)\n",
    "OLD2 = OLD.append(ratings)\n",
    "OLD2.to_csv(os.path.join(DATA_PATH, 'OLD(02.03RF).csv'))\n",
    "OLD2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLD2.to_csv(os.path.join(DATA_PATH, 'OLD2(1).csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9724459 entries, 0 to 438789\n",
      "Data columns (total 4 columns):\n",
      "element_uid    int64\n",
      "rating         float64\n",
      "ts             float64\n",
      "user_uid       int64\n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 371.0 MB\n"
     ]
    }
   ],
   "source": [
    "OLD2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import mglearn\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "(transactions_exp.isnull().sum()/transactions_exp.shape[0]).plot(kind='bar');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
